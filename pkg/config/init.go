package config

import (
	"fmt"
	"os"
	"path/filepath"
)

// InitConfig creates a sample configuration file at the default location.
//
// This function:
//  1. Creates the config directory if it doesn't exist
//  2. Generates a config file with defaults and helpful comments
//  3. Returns an error if the file already exists (won't overwrite)
//
// Parameters:
//   - force: If true, overwrite existing config file
//
// Returns:
//   - string: Path to the created config file
//   - error: File creation error or file already exists
func InitConfig(force bool) (string, error) {
	configPath := GetDefaultConfigPath()
	configDir := filepath.Dir(configPath)

	// Create config directory if it doesn't exist
	if err := os.MkdirAll(configDir, 0755); err != nil {
		return "", fmt.Errorf("failed to create config directory: %w", err)
	}

	// Check if config already exists
	if !force && DefaultConfigExists() {
		return "", fmt.Errorf("config file already exists at %s (use --force to overwrite)", configPath)
	}

	// Generate sample config
	cfg := GetDefaultConfig()

	// Marshal to YAML with comments
	yamlData, err := generateYAMLWithComments(cfg)
	if err != nil {
		return "", fmt.Errorf("failed to generate YAML: %w", err)
	}

	// Write to file
	if err := os.WriteFile(configPath, []byte(yamlData), 0644); err != nil {
		return "", fmt.Errorf("failed to write config file: %w", err)
	}

	return configPath, nil
}

// generateYAMLWithComments generates a YAML config file with helpful comments.
func generateYAMLWithComments(cfg *Config) (string, error) {
	// We'll build the YAML manually with comments for better UX
	// This is more maintainable than trying to preserve comments through yaml.Marshal

	// Get first store names for the example
	var metadataStoreName, contentStoreName string
	var metadataStore MetadataStoreConfig
	var contentStore ContentStoreConfig

	for name, store := range cfg.Metadata.Stores {
		metadataStoreName = name
		metadataStore = store
		break
	}
	for name, store := range cfg.Content.Stores {
		contentStoreName = name
		contentStore = store
		break
	}

	yaml := `# DittoFS Configuration File
# This file is automatically generated with default values.
# Modify as needed for your environment.

# Logging configuration
logging:
  # Log level: DEBUG, INFO, WARN, ERROR
  level: "` + cfg.Logging.Level + `"
  # Log format: text, json
  format: "` + cfg.Logging.Format + `"
  # Log output: stdout, stderr, or file path
  output: "` + cfg.Logging.Output + `"

# Server-wide settings
server:
  # Maximum time to wait for graceful shutdown
  shutdown_timeout: ` + cfg.Server.ShutdownTimeout.String() + `

# Metadata store configuration
metadata:
  # Global settings for all metadata stores
  global:
    # Filesystem capabilities and limits
    filesystem_capabilities:
      # Maximum size of a single read operation (bytes)
      max_read_size: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxReadSize) + `
      # Preferred read size for optimal performance (bytes)
      preferred_read_size: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.PreferredReadSize) + `
      # Maximum size of a single write operation (bytes)
      max_write_size: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxWriteSize) + `
      # Preferred write size for optimal performance (bytes)
      preferred_write_size: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.PreferredWriteSize) + `
      # Maximum file size supported (bytes)
      max_file_size: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxFileSize) + `
      # Maximum filename length (characters)
      max_filename_len: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxFilenameLen) + `
      # Maximum path length (characters)
      max_path_len: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxPathLen) + `
      # Maximum number of hard links per file
      max_hard_link_count: ` + fmt.Sprintf("%d", cfg.Metadata.Global.FilesystemCapabilities.MaxHardLinkCount) + `
      # Whether hard links are supported
      supports_hard_links: ` + fmt.Sprintf("%t", cfg.Metadata.Global.FilesystemCapabilities.SupportsHardLinks) + `
      # Whether symbolic links are supported
      supports_symlinks: ` + fmt.Sprintf("%t", cfg.Metadata.Global.FilesystemCapabilities.SupportsSymlinks) + `
      # Whether filenames are case-sensitive
      case_sensitive: ` + fmt.Sprintf("%t", cfg.Metadata.Global.FilesystemCapabilities.CaseSensitive) + `
      # Whether filename case is preserved
      case_preserving: ` + fmt.Sprintf("%t", cfg.Metadata.Global.FilesystemCapabilities.CasePreserving) + `

  # Named metadata store instances
  stores:
    ` + metadataStoreName + `:
      # Metadata store type: memory, badger
      type: "` + metadataStore.Type + `"`

	// Add type-specific configuration
	if metadataStore.Type == "badger" {
		yaml += `
      # BadgerDB configuration
      badger:
        # Directory path for BadgerDB database
        db_path: "` + fmt.Sprintf("%v", metadataStore.Badger["db_path"]) + `"`
	} else if metadataStore.Type == "memory" {
		yaml += `
      # Memory store has no specific configuration
      memory: {}`
	}

	yaml += `

# Content store configuration
content:
  # Global settings for all content stores
  global: {}

  # Named content store instances
  stores:
    ` + contentStoreName + `:
      # Content store type: filesystem, memory, s3
      type: "` + contentStore.Type + `"`

	// Add type-specific configuration
	if contentStore.Type == "filesystem" {
		yaml += `
      # Filesystem configuration
      filesystem:
        # Directory path for storing file content
        path: "` + fmt.Sprintf("%v", contentStore.Filesystem["path"]) + `"`
	} else if contentStore.Type == "memory" {
		yaml += `
      # Memory configuration
      memory:
        # Maximum total size of content in bytes (0 = unlimited)
        max_size_bytes: ` + fmt.Sprintf("%v", contentStore.Memory["max_size_bytes"])
	} else if contentStore.Type == "s3" {
		yaml += `
      # S3 configuration
      s3:
        region: "` + fmt.Sprintf("%v", contentStore.S3["region"]) + `"
        bucket: "` + fmt.Sprintf("%v", contentStore.S3["bucket"]) + `"`
	}

	yaml += `

# Shares/Exports configuration
shares:
  - # Share path (must start with /)
    name: "` + cfg.Shares[0].Name + `"
    # Reference to metadata store by name
    metadata_store: "` + cfg.Shares[0].MetadataStore + `"
    # Reference to content store by name
    content_store: "` + cfg.Shares[0].ContentStore + `"
    # Make share read-only
    read_only: ` + fmt.Sprintf("%t", cfg.Shares[0].ReadOnly) + `
    # Allow asynchronous writes
    async: ` + fmt.Sprintf("%t", cfg.Shares[0].Async) + `
    # IP addresses or CIDR ranges allowed to access (empty = all)
    allowed_clients: []
    # IP addresses or CIDR ranges explicitly denied
    denied_clients: []
    # Require authentication
    require_auth: ` + fmt.Sprintf("%t", cfg.Shares[0].RequireAuth) + `
    # Allowed authentication methods: anonymous, unix
    allowed_auth_methods:
      - "anonymous"
      - "unix"
    # Identity mapping configuration
    identity_mapping:
      # Map all users to anonymous (all_squash)
      map_all_to_anonymous: ` + fmt.Sprintf("%t", cfg.Shares[0].IdentityMapping.MapAllToAnonymous) + `
      # Map root user to anonymous (root_squash)
      map_privileged_to_anonymous: ` + fmt.Sprintf("%t", cfg.Shares[0].IdentityMapping.MapPrivilegedToAnonymous) + `
      # UID for anonymous users
      anonymous_uid: ` + fmt.Sprintf("%d", cfg.Shares[0].IdentityMapping.AnonymousUID) + `
      # GID for anonymous users
      anonymous_gid: ` + fmt.Sprintf("%d", cfg.Shares[0].IdentityMapping.AnonymousGID) + `
    # Root directory attributes
    root_directory_attributes:
      # Unix permission mode (octal)
      mode: ` + fmt.Sprintf("0%o", cfg.Shares[0].RootDirectoryAttributes.Mode) + `
      # Owner user ID
      uid: ` + fmt.Sprintf("%d", cfg.Shares[0].RootDirectoryAttributes.UID) + `
      # Owner group ID
      gid: ` + fmt.Sprintf("%d", cfg.Shares[0].RootDirectoryAttributes.GID) + `
    # Restrict DUMP operations to allowed clients only
    dump_restricted: ` + fmt.Sprintf("%t", cfg.Shares[0].DumpRestricted) + `
    # IP addresses or CIDR ranges allowed to use DUMP (only used if dump_restricted=true)
    dump_allowed_clients: []

# Protocol adapters configuration
adapters:
  # NFS adapter configuration
  nfs:
    # Enable NFS adapter
    enabled: ` + fmt.Sprintf("%t", cfg.Adapters.NFS.Enabled) + `
    # TCP port to listen on
    port: ` + fmt.Sprintf("%d", cfg.Adapters.NFS.Port) + `
    # Maximum concurrent connections (0 = unlimited)
    max_connections: ` + fmt.Sprintf("%d", cfg.Adapters.NFS.MaxConnections) + `
    # Timeout configuration
    timeouts:
      # Maximum time to read a request
      read: ` + cfg.Adapters.NFS.Timeouts.Read.String() + `
      # Maximum time to write a response
      write: ` + cfg.Adapters.NFS.Timeouts.Write.String() + `
      # Maximum idle time between requests
      idle: ` + cfg.Adapters.NFS.Timeouts.Idle.String() + `
      # Graceful shutdown timeout
      shutdown: ` + cfg.Adapters.NFS.Timeouts.Shutdown.String() + `
    # Metrics logging interval (0 = disabled)
    metrics_log_interval: ` + cfg.Adapters.NFS.MetricsLogInterval.String() + `
`

	return yaml, nil
}

// InitConfigToPath creates a sample configuration file at the specified path.
//
// Similar to InitConfig but allows specifying a custom path.
//
// Parameters:
//   - path: Full path to the config file to create
//   - force: If true, overwrite existing config file
//
// Returns:
//   - error: File creation error or file already exists
func InitConfigToPath(path string, force bool) error {
	configDir := filepath.Dir(path)

	// Create config directory if it doesn't exist
	if err := os.MkdirAll(configDir, 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// Check if config already exists
	if !force {
		if _, err := os.Stat(path); err == nil {
			return fmt.Errorf("config file already exists at %s (use --force to overwrite)", path)
		}
	}

	// Generate sample config with comments
	cfg := GetDefaultConfig()

	// Generate YAML with helpful comments
	yamlData, err := generateYAMLWithComments(cfg)
	if err != nil {
		return fmt.Errorf("failed to generate config: %w", err)
	}

	// Write to file
	if err := os.WriteFile(path, []byte(yamlData), 0644); err != nil {
		return fmt.Errorf("failed to write config file: %w", err)
	}

	return nil
}
