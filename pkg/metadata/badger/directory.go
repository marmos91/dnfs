package badger

import (
	"fmt"
	"strconv"
	"sync/atomic"
	"time"

	badger "github.com/dgraph-io/badger/v4"
	"github.com/marmos91/dittofs/internal/logger"
	"github.com/marmos91/dittofs/pkg/metadata"
)

// ReadDirectory reads one page of directory entries with pagination support.
//
// Pagination uses opaque tokens (offset-based in this implementation).
// This uses a BadgerDB read transaction with an iterator to scan children.
//
// Thread Safety: Safe for concurrent use.
//
// Parameters:
//   - ctx: Authentication context for permission checking
//   - dirHandle: Directory to read
//   - token: Pagination token (empty string = start, or offset from previous page)
//   - maxBytes: Maximum response size hint in bytes (0 = use default of 8192)
//
// Returns:
//   - *ReadDirPage: Page of entries with pagination info
//   - error: Various errors based on validation failures
func (s *BadgerMetadataStore) ReadDirectory(
	ctx *metadata.AuthContext,
	dirHandle metadata.FileHandle,
	token string,
	maxBytes uint32,
) (*metadata.ReadDirPage, error) {
	// Check context cancellation
	if err := ctx.Context.Err(); err != nil {
		return nil, err
	}

	// Check read and execute permissions BEFORE acquiring lock to avoid unlock/relock race
	var granted metadata.Permission
	var err error
	granted, err = s.CheckPermissions(ctx, dirHandle,
		metadata.PermissionRead|metadata.PermissionTraverse)
	if err != nil {
		return nil, err
	}
	if granted&metadata.PermissionRead == 0 || granted&metadata.PermissionTraverse == 0 {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrAccessDenied,
			Message: "no read or execute permission on directory",
		}
	}

	// Acquire read lock BEFORE checking cache to ensure cache consistency.
	// The generation counter mechanism provides additional protection against
	// serving stale cached data during concurrent modifications.
	s.mu.RLock()
	defer s.mu.RUnlock()

	// Capture generation before checking cache
	var startGeneration uint64
	s.readdirCache.mu.RLock()
	startGeneration = s.readdirCache.generation
	s.readdirCache.mu.RUnlock()

	// Try cache if cache is enabled
	// Note: token can be non-empty for paginated reads from cache
	if s.readdirCache.enabled {
		cached := s.getReaddirCached(dirHandle)
		if cached != nil {
			// Re-check generation to detect concurrent modifications
			s.readdirCache.mu.RLock()
			currentGeneration := s.readdirCache.generation
			s.readdirCache.mu.RUnlock()

			// Validate cached entry is from current generation AND generation hasn't changed
			if cached.generation == currentGeneration && currentGeneration == startGeneration {
				// Cached data is valid and generation unchanged - safe to use
				atomic.AddUint64(&s.readdirCache.hits, 1)

				// Parse pagination token
				startIdx := 0
				if token != "" {
					var err error
					startIdx, err = strconv.Atoi(token)
					if err != nil || startIdx < 0 || startIdx > len(cached.names) {
						return nil, &metadata.StoreError{
							Code:    metadata.ErrInvalidArgument,
							Message: "invalid pagination token",
						}
					}
				}

				// Use default maxBytes if not specified (same as uncached path)
				pageSize := maxBytes
				if pageSize == 0 {
					pageSize = 8192 // Default from NFS spec
				}

				// Apply pagination to cached entries
				var entries []metadata.DirEntry
				var totalBytes uint32
				nextIdx := startIdx

				for nextIdx < len(cached.names) {
					entry := metadata.DirEntry{
						ID:     fileHandleToID(cached.children[nextIdx]),
						Name:   cached.names[nextIdx],
						Handle: cached.children[nextIdx], // Avoid Lookup() in READDIRPLUS
						Attr:   nil,                       // TODO: Could cache attrs too
					}
					// Estimate entry size: 8 bytes for ID + len(Name) + 16 bytes overhead
					entrySize := uint32(8 + len(entry.Name) + 16)

					// If adding this entry would exceed pageSize and we have at least one entry, stop
					if totalBytes+entrySize > pageSize && len(entries) > 0 {
						break
					}

					totalBytes += entrySize
					entries = append(entries, entry)
					nextIdx++
				}

				// Determine if there are more entries
				hasMore := nextIdx < len(cached.names)
				nextToken := ""
				if hasMore {
					nextToken = strconv.Itoa(nextIdx)
				}

				return &metadata.ReadDirPage{
					Entries:   entries,
					NextToken: nextToken,
					HasMore:   hasMore,
				}, nil
			} else {
				// Generation changed - fall through to DB read
				// Note: We don't call invalidateReaddir() here to avoid potential deadlock
				// (holding s.mu.RLock while invalidateReaddir acquires readdirCache.mu.Lock).
				// The generation check already prevents stale reads, and the cache entry
				// will be naturally evicted by LRU or expire by TTL.
				atomic.AddUint64(&s.readdirCache.misses, 1)
			}
		} else {
			atomic.AddUint64(&s.readdirCache.misses, 1)
		}
	}

	// Loop until we get a consistent snapshot (generation unchanged during read)
	// This ensures we NEVER return handles to deleted files
	var page *metadata.ReadDirPage
	var allChildren []metadata.FileHandle
	var allNames []string
	maxAttempts := 5 // Prevent infinite loops in pathological cases

	for attempt := 1; attempt <= maxAttempts; attempt++ {
		// Capture generation right before DB read
		s.readdirCache.mu.RLock()
		startGeneration = s.readdirCache.generation
		s.readdirCache.mu.RUnlock()

		// Reset for retry
		allChildren = nil
		allNames = nil

		err = s.db.View(func(txn *badger.Txn) error {
		// Get directory data
		item, err := txn.Get(keyFile(dirHandle))
		if err == badger.ErrKeyNotFound {
			return &metadata.StoreError{
				Code:    metadata.ErrNotFound,
				Message: "directory not found",
			}
		}
		if err != nil {
			return fmt.Errorf("failed to get directory: %w", err)
		}

		var dirData *fileData
		err = item.Value(func(val []byte) error {
			dd, err := decodeFileData(val)
			if err != nil {
				return err
			}
			dirData = dd
			return nil
		})
		if err != nil {
			return err
		}

		// Verify it's a directory
		if dirData.Attr.Type != metadata.FileTypeDirectory {
			return &metadata.StoreError{
				Code:    metadata.ErrNotDirectory,
				Message: "not a directory",
			}
		}

		// Parse token
		offset := 0
		if token != "" {
			parsedOffset, err := strconv.Atoi(token)
			if err != nil {
				return &metadata.StoreError{
					Code:    metadata.ErrInvalidArgument,
					Message: "invalid pagination token",
				}
			}
			offset = parsedOffset
		}

		// Default maxBytes
		if maxBytes == 0 {
			maxBytes = 8192
		}

		// Scan children using range iterator
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = true
		opts.Prefix = keyChildPrefix(dirHandle)

		it := txn.NewIterator(opts)
		defer it.Close()

		var entries []metadata.DirEntry
		var estimatedSize uint32
		currentOffset := 0

		for it.Rewind(); it.Valid(); it.Next() {
			// Check context periodically
			if currentOffset%100 == 0 {
				if err := ctx.Context.Err(); err != nil {
					return err
				}
			}

			item := it.Item()
			key := item.Key()

			// Extract child name from key: "c:<parent>:<name>"
			prefix := keyChildPrefix(dirHandle)
			if len(key) <= len(prefix) {
				continue
			}
			childName := string(key[len(prefix):])

			// Get child handle
			var childHandle metadata.FileHandle
			err = item.Value(func(val []byte) error {
				childHandle = metadata.FileHandle(val)
				return nil
			})
			if err != nil {
				return err
			}

			// Skip entries before offset (but still track for caching)
			if currentOffset < offset {
				// Track all children for caching (if reading from start)
				// Must track even skipped entries to build complete cache
				if token == "" {
					allChildren = append(allChildren, childHandle)
					allNames = append(allNames, childName)
				}
				currentOffset++
				continue
			}

			// Track all children for caching (if reading from start)
			if token == "" {
				allChildren = append(allChildren, childHandle)
				allNames = append(allNames, childName)
			}

			// Create directory entry
			// DirEntry uses file ID (uint64) - compute hash of handle for ID
			entry := metadata.DirEntry{
				ID:     fileHandleToID(childHandle),
				Name:   childName,
				Handle: childHandle, // Avoid Lookup() in READDIRPLUS
				Attr:   nil,         // TODO: Could populate from cache for further optimization
			}

			// Estimate size (rough estimate: name + some overhead)
			entrySize := uint32(len(childName) + 200) // Rough estimate
			if estimatedSize+entrySize > maxBytes && len(entries) > 0 {
				// Reached size limit, stop here
				page = &metadata.ReadDirPage{
					Entries:   entries,
					NextToken: strconv.Itoa(currentOffset),
					HasMore:   true,
				}
				return nil
			}

			entries = append(entries, entry)
			estimatedSize += entrySize
			currentOffset++
		}

		// No more entries
		page = &metadata.ReadDirPage{
			Entries:   entries,
			NextToken: "",
			HasMore:   false,
		}

		return nil
	})

		if err != nil {
			return nil, err
		}

		// Check if generation changed during our read
		s.readdirCache.mu.RLock()
		currentGeneration := s.readdirCache.generation
		s.readdirCache.mu.RUnlock()

		// If generation unchanged, we have consistent data - break out of retry loop
		if currentGeneration == startGeneration {
			// Cache and return consistent data
			if token == "" {
				s.putReaddirCached(dirHandle, allChildren, allNames)
			}
			return page, nil
		}

		// Generation changed - data may be stale, retry
		if attempt < maxAttempts {
			logger.Debug("ReadDirectory: concurrent modification detected (gen %d â†’ %d), retrying (attempt %d/%d)",
				startGeneration, currentGeneration, attempt, maxAttempts)
			continue
		}

		// Max retries exceeded - this shouldn't happen in practice
		logger.Warn("ReadDirectory: max retries exceeded due to concurrent modifications: dir=%s attempts=%d",
			dirHandle, maxAttempts)
		return nil, &metadata.StoreError{
			Code:    metadata.ErrNotFound,
			Message: "directory unstable due to concurrent modifications",
		}
	}

	// Should never reach here
	return nil, &metadata.StoreError{
		Code:    metadata.ErrNotFound,
		Message: "unexpected error in ReadDirectory",
	}
}

// ReadSymlink reads the target path of a symbolic link.
//
// This returns the path stored in the symlink without following it or validating
// that the target exists. Also returns the symlink's attributes for cache consistency.
//
// Thread Safety: Safe for concurrent use.
//
// Parameters:
//   - ctx: Authentication context for permission checking
//   - handle: File handle of the symbolic link
//
// Returns:
//   - string: The target path stored in the symlink
//   - *FileAttr: Attributes of the symlink itself (not the target)
//   - error: ErrNotFound, ErrInvalidArgument, ErrAccessDenied, or context errors
func (s *BadgerMetadataStore) ReadSymlink(
	ctx *metadata.AuthContext,
	handle metadata.FileHandle,
) (string, *metadata.FileAttr, error) {
	// Check context cancellation
	if err := ctx.Context.Err(); err != nil {
		return "", nil, err
	}

	// Check read permission BEFORE acquiring lock to avoid unlock/relock race
	granted, err := s.CheckPermissions(ctx, handle, metadata.PermissionRead)
	if err != nil {
		return "", nil, err
	}
	if granted&metadata.PermissionRead == 0 {
		return "", nil, &metadata.StoreError{
			Code:    metadata.ErrAccessDenied,
			Message: "no read permission on symlink",
		}
	}

	s.mu.RLock()
	defer s.mu.RUnlock()

	var target string
	var attr *metadata.FileAttr

	err = s.db.View(func(txn *badger.Txn) error {
		// Get file data
		item, err := txn.Get(keyFile(handle))
		if err == badger.ErrKeyNotFound {
			return &metadata.StoreError{
				Code:    metadata.ErrNotFound,
				Message: "file not found",
			}
		}
		if err != nil {
			return fmt.Errorf("failed to get file: %w", err)
		}

		var fileData *fileData
		err = item.Value(func(val []byte) error {
			fd, err := decodeFileData(val)
			if err != nil {
				return err
			}
			fileData = fd
			return nil
		})
		if err != nil {
			return err
		}

		// Verify it's a symlink
		if fileData.Attr.Type != metadata.FileTypeSymlink {
			return &metadata.StoreError{
				Code:    metadata.ErrInvalidArgument,
				Message: "not a symbolic link",
			}
		}

		target = fileData.Attr.LinkTarget
		attr = fileData.Attr

		return nil
	})

	if err != nil {
		return "", nil, err
	}

	// Return copy of attributes
	attrCopy := *attr
	return target, &attrCopy, nil
}

// CreateSymlink creates a symbolic link pointing to a target path.
//
// This uses a BadgerDB write transaction to ensure atomicity.
//
// Thread Safety: Safe for concurrent use.
//
// Parameters:
//   - ctx: Authentication context for permission checking
//   - parentHandle: Handle of the parent directory
//   - name: Name for the new symlink
//   - target: Path the symlink will point to (can be absolute or relative)
//   - attr: Partial attributes (mode, uid, gid may be set)
//
// Returns:
//   - FileHandle: Handle of the newly created symlink
//   - error: Various errors based on validation failures
func (s *BadgerMetadataStore) CreateSymlink(
	ctx *metadata.AuthContext,
	parentHandle metadata.FileHandle,
	name string,
	target string,
	attr *metadata.FileAttr,
) (metadata.FileHandle, error) {
	// Check context cancellation
	if err := ctx.Context.Err(); err != nil {
		return nil, err
	}

	// Validate name
	if name == "" || name == "." || name == ".." {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrInvalidArgument,
			Message: "invalid name",
			Path:    name,
		}
	}

	// Validate target
	if target == "" {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrInvalidArgument,
			Message: "symlink target cannot be empty",
		}
	}

	// Check write permission BEFORE acquiring lock to avoid unlock/relock race
	granted, err := s.CheckPermissions(ctx, parentHandle, metadata.PermissionWrite)
	if err != nil {
		return nil, err
	}
	if granted&metadata.PermissionWrite == 0 {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrAccessDenied,
			Message: "no write permission on parent directory",
		}
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	var newHandle metadata.FileHandle

	err = s.db.Update(func(txn *badger.Txn) error {
		// Verify parent exists and is a directory
		item, err := txn.Get(keyFile(parentHandle))
		if err == badger.ErrKeyNotFound {
			return &metadata.StoreError{
				Code:    metadata.ErrNotFound,
				Message: "parent directory not found",
			}
		}
		if err != nil {
			return fmt.Errorf("failed to get parent: %w", err)
		}

		var parentData *fileData
		err = item.Value(func(val []byte) error {
			pd, err := decodeFileData(val)
			if err != nil {
				return err
			}
			parentData = pd
			return nil
		})
		if err != nil {
			return err
		}

		if parentData.Attr.Type != metadata.FileTypeDirectory {
			return &metadata.StoreError{
				Code:    metadata.ErrNotDirectory,
				Message: "parent is not a directory",
			}
		}

		// Check if name already exists
		_, err = txn.Get(keyChild(parentHandle, name))
		if err == nil {
			return &metadata.StoreError{
				Code:    metadata.ErrAlreadyExists,
				Message: fmt.Sprintf("name already exists: %s", name),
				Path:    name,
			}
		} else if err != badger.ErrKeyNotFound {
			return fmt.Errorf("failed to check child existence: %w", err)
		}

		// Build full path and generate deterministic handle
		fullPath, err := buildFullPath(s, parentHandle, name)
		if err != nil {
			return fmt.Errorf("failed to build full path: %w", err)
		}

		handle, isPathBased := generateFileHandle(parentData.ShareName, fullPath)
		newHandle = handle

		// If hash-based, store the reverse mapping
		if !isPathBased {
			if err := storeHashedHandleMapping(txn, handle, parentData.ShareName, fullPath); err != nil {
				return fmt.Errorf("failed to store handle mapping: %w", err)
			}
		}

		now := time.Now()

		// Set defaults
		mode := attr.Mode
		if mode == 0 {
			mode = 0777 // Symlinks typically have 0777
		}

		uid := attr.UID
		gid := attr.GID
		if ctx.Identity != nil && ctx.Identity.UID != nil {
			if uid == 0 {
				uid = *ctx.Identity.UID
			}
			if gid == 0 && ctx.Identity.GID != nil {
				gid = *ctx.Identity.GID
			}
		}

		// Create symlink attributes
		newAttr := &metadata.FileAttr{
			Type:       metadata.FileTypeSymlink,
			Mode:       mode & 0o7777,
			UID:        uid,
			GID:        gid,
			Size:       uint64(len(target)),
			Atime:      now,
			Mtime:      now,
			Ctime:      now,
			LinkTarget: target,
			ContentID:  "",
		}

		// Store symlink
		fileData := &fileData{
			Attr:      newAttr,
			ShareName: parentData.ShareName,
		}
		fileBytes, err := encodeFileData(fileData)
		if err != nil {
			return err
		}
		if err := txn.Set(keyFile(handle), fileBytes); err != nil {
			return fmt.Errorf("failed to store symlink: %w", err)
		}

		// Set link count
		if err := txn.Set(keyLinkCount(handle), encodeUint32(1)); err != nil {
			return fmt.Errorf("failed to store link count: %w", err)
		}

		// Add to parent's children
		if err := txn.Set(keyChild(parentHandle, name), []byte(handle)); err != nil {
			return fmt.Errorf("failed to add child: %w", err)
		}

		// Set parent relationship
		if err := txn.Set(keyParent(handle), []byte(parentHandle)); err != nil {
			return fmt.Errorf("failed to set parent: %w", err)
		}

		// Update parent timestamps
		parentData.Attr.Mtime = now
		parentData.Attr.Ctime = now
		parentBytes, err := encodeFileData(parentData)
		if err != nil {
			return err
		}
		if err := txn.Set(keyFile(parentHandle), parentBytes); err != nil {
			return fmt.Errorf("failed to update parent: %w", err)
		}

		return nil
	})

	if err != nil {
		return nil, err
	}

	// Invalidate directory caches for parent directory
	s.invalidateDirectory(parentHandle)

	return newHandle, nil
}

// CreateSpecialFile creates a special file (device, socket, or FIFO).
//
// This uses a BadgerDB write transaction to ensure atomicity.
//
// Thread Safety: Safe for concurrent use.
//
// Parameters:
//   - ctx: Authentication context for permission checking
//   - parentHandle: Handle of the parent directory
//   - name: Name for the new special file
//   - fileType: Type of special file to create
//   - attr: Partial attributes (mode, uid, gid may be set)
//   - deviceMajor: Major device number (for block/char devices, 0 otherwise)
//   - deviceMinor: Minor device number (for block/char devices, 0 otherwise)
//
// Returns:
//   - FileHandle: Handle of the newly created special file
//   - error: Various errors based on validation failures
func (s *BadgerMetadataStore) CreateSpecialFile(
	ctx *metadata.AuthContext,
	parentHandle metadata.FileHandle,
	name string,
	fileType metadata.FileType,
	attr *metadata.FileAttr,
	deviceMajor, deviceMinor uint32,
) (metadata.FileHandle, error) {
	// Check context cancellation
	if err := ctx.Context.Err(); err != nil {
		return nil, err
	}

	// Validate file type
	switch fileType {
	case metadata.FileTypeBlockDevice, metadata.FileTypeCharDevice,
		metadata.FileTypeSocket, metadata.FileTypeFIFO:
		// Valid special file types
	default:
		return nil, &metadata.StoreError{
			Code:    metadata.ErrInvalidArgument,
			Message: fmt.Sprintf("invalid special file type: %d", fileType),
		}
	}

	// Validate name
	if name == "" || name == "." || name == ".." {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrInvalidArgument,
			Message: "invalid name",
			Path:    name,
		}
	}

	// Check if user is root (required for device files)
	if fileType == metadata.FileTypeBlockDevice || fileType == metadata.FileTypeCharDevice {
		if ctx.Identity == nil || ctx.Identity.UID == nil || *ctx.Identity.UID != 0 {
			return nil, &metadata.StoreError{
				Code:    metadata.ErrAccessDenied,
				Message: "only root can create device files",
			}
		}
	}

	// Check write permission BEFORE acquiring lock to avoid unlock/relock race
	granted, err := s.CheckPermissions(ctx, parentHandle, metadata.PermissionWrite)
	if err != nil {
		return nil, err
	}
	if granted&metadata.PermissionWrite == 0 {
		return nil, &metadata.StoreError{
			Code:    metadata.ErrAccessDenied,
			Message: "no write permission on parent directory",
		}
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	var newHandle metadata.FileHandle

	err = s.db.Update(func(txn *badger.Txn) error {
		// Verify parent exists and is a directory
		item, err := txn.Get(keyFile(parentHandle))
		if err == badger.ErrKeyNotFound {
			return &metadata.StoreError{
				Code:    metadata.ErrNotFound,
				Message: "parent directory not found",
			}
		}
		if err != nil {
			return fmt.Errorf("failed to get parent: %w", err)
		}

		var parentData *fileData
		err = item.Value(func(val []byte) error {
			pd, err := decodeFileData(val)
			if err != nil {
				return err
			}
			parentData = pd
			return nil
		})
		if err != nil {
			return err
		}

		if parentData.Attr.Type != metadata.FileTypeDirectory {
			return &metadata.StoreError{
				Code:    metadata.ErrNotDirectory,
				Message: "parent is not a directory",
			}
		}

		// Check if name already exists
		_, err = txn.Get(keyChild(parentHandle, name))
		if err == nil {
			return &metadata.StoreError{
				Code:    metadata.ErrAlreadyExists,
				Message: fmt.Sprintf("name already exists: %s", name),
				Path:    name,
			}
		} else if err != badger.ErrKeyNotFound {
			return fmt.Errorf("failed to check child existence: %w", err)
		}

		// Build full path and generate deterministic handle
		fullPath, err := buildFullPath(s, parentHandle, name)
		if err != nil {
			return fmt.Errorf("failed to build full path: %w", err)
		}

		handle, isPathBased := generateFileHandle(parentData.ShareName, fullPath)
		newHandle = handle

		// If hash-based, store the reverse mapping
		if !isPathBased {
			if err := storeHashedHandleMapping(txn, handle, parentData.ShareName, fullPath); err != nil {
				return fmt.Errorf("failed to store handle mapping: %w", err)
			}
		}

		now := time.Now()

		// Set defaults
		mode := attr.Mode
		if mode == 0 {
			mode = 0644
		}

		uid := attr.UID
		gid := attr.GID
		if ctx.Identity != nil && ctx.Identity.UID != nil {
			if uid == 0 {
				uid = *ctx.Identity.UID
			}
			if gid == 0 && ctx.Identity.GID != nil {
				gid = *ctx.Identity.GID
			}
		}

		// Create special file attributes
		newAttr := &metadata.FileAttr{
			Type:       fileType,
			Mode:       mode & 0o7777,
			UID:        uid,
			GID:        gid,
			Size:       0,
			Atime:      now,
			Mtime:      now,
			Ctime:      now,
			LinkTarget: "",
			ContentID:  "",
		}

		// Store special file
		fileData := &fileData{
			Attr:      newAttr,
			ShareName: parentData.ShareName,
		}
		fileBytes, err := encodeFileData(fileData)
		if err != nil {
			return err
		}
		if err := txn.Set(keyFile(handle), fileBytes); err != nil {
			return fmt.Errorf("failed to store special file: %w", err)
		}

		// Store device numbers if applicable
		if fileType == metadata.FileTypeBlockDevice || fileType == metadata.FileTypeCharDevice {
			devNum := &deviceNumber{
				Major: deviceMajor,
				Minor: deviceMinor,
			}
			devBytes, err := encodeDeviceNumber(devNum)
			if err != nil {
				return err
			}
			if err := txn.Set(keyDeviceNumber(handle), devBytes); err != nil {
				return fmt.Errorf("failed to store device numbers: %w", err)
			}
		}

		// Set link count
		if err := txn.Set(keyLinkCount(handle), encodeUint32(1)); err != nil {
			return fmt.Errorf("failed to store link count: %w", err)
		}

		// Add to parent's children
		if err := txn.Set(keyChild(parentHandle, name), []byte(handle)); err != nil {
			return fmt.Errorf("failed to add child: %w", err)
		}

		// Set parent relationship
		if err := txn.Set(keyParent(handle), []byte(parentHandle)); err != nil {
			return fmt.Errorf("failed to set parent: %w", err)
		}

		// Update parent timestamps
		parentData.Attr.Mtime = now
		parentData.Attr.Ctime = now
		parentBytes, err := encodeFileData(parentData)
		if err != nil {
			return err
		}
		if err := txn.Set(keyFile(parentHandle), parentBytes); err != nil {
			return fmt.Errorf("failed to update parent: %w", err)
		}

		return nil
	})

	if err != nil {
		return nil, err
	}

	// Invalidate directory caches for parent directory
	s.invalidateDirectory(parentHandle)

	return newHandle, nil
}
